{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Reading From Dataset\n",
    "First and foremost, we'll need a dataset to train your model because it's virtually impossible to complete a machine-learning project without one, right? :) We can easily read the dataset thanks to [Hossein Zaredar](https://github.com/HosseinZaredar/Computational-Intelligence/blob/main/read_MNIST.py)'s help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "NUMBER_OF_PIXELS = 784"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read from the files, we construct a function named `read_from_file` that does nothing but that.We know where to look for each data based on the information given by MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_file(image_address, label_address):\n",
    "    images_file = open(image_address, 'rb')\n",
    "    images_file.seek(4)  # Positions the cursor to the 4th byte.\n",
    "    number_of_images = int.from_bytes(images_file.read(4), 'big')  # reads 4 bytes in big endian order\n",
    "    images_file.seek(16)  # Positions the cursor to the 16th byte.\n",
    "    \n",
    "    labels_file = open(label_address, 'rb')\n",
    "    labels_file.seek(8)\n",
    "    \n",
    "    result_set = []\n",
    "    for n in range(number_of_images):\n",
    "        image = np.zeros((NUMBER_OF_PIXELS, 1))\n",
    "        for i in range(NUMBER_OF_PIXELS):\n",
    "            image[i, 0] = int.from_bytes(images_file.read(1), 'big') / 255\n",
    "\n",
    "        label_value = int.from_bytes(labels_file.read(1), 'big')\n",
    "        label = np.zeros((10, 1))  # Since we have 10 numbers from 0 to 9\n",
    "        label[label_value, 0] = 1\n",
    "\n",
    "        result_set.append((image, label))\n",
    "    \n",
    "    return result_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then we call that function to create our train & test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = read_from_file(\"digit_images/train-images.idx3-ubyte\", \"digit_images/train-labels.idx1-ubyte\")\n",
    "test_set = read_from_file(\"digit_images/t10k-images.idx3-ubyte\", \"digit_images/t10k-labels.idx1-ubyte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of this section, we plot an image just to make sure we've done this part rightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_set[0][0].reshape(28, -1), 'gray')\n",
    "train_set[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feedforward\n",
    "As we all know, in order to calculate output in a neural network based on inputs, we must apply the following formula on each layer:  \n",
    "$$a^{(L+1)} = \\sigma(W^{(L+1)}× a^{(L)} + b^{(L+1)})$$\n",
    "\n",
    "Therefore in implementation, for weights between layers, we assign a k×n matrix. Assume \"k\" is the number of neurons on the next layer, and \"n\" is the number of neurons on the current layer. As a result, the weights of a single neuron on the next layer are shown in each row of our matrix W."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate W matrix and vector b for each layer.\n",
    "\n",
    "# Initialize W from standard normal distribution\n",
    "W1 = np.random.normal(size=(16, NUMBER_OF_PIXELS))\n",
    "W2 = np.random.normal(size=(16, 16))\n",
    "W3 = np.random.normal(size=(10, 16))\n",
    "\n",
    "# Initialize b = 0, for each layer.\n",
    "b1 = np.zeros((16, 1))\n",
    "b2 = np.zeros((16, 1))\n",
    "b3 = np.zeros((10, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this step of this project, after initializing W matrices and bias vectors, we separate the first 100 images of our train dataset and calculate the output of that based on the given formula.\n",
    "\n",
    "In the end, we report the accuracy, which is the number of true estimations divided by the number of images (which is 100 in our scenario). Regarding that the learning process has not proceeded, we expect to have an accuracy of around 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.14\n"
     ]
    }
   ],
   "source": [
    "number_of_correct_estimations = 0\n",
    "total_numbers = 100\n",
    "\n",
    "for train_data in train_set[:total_numbers]:\n",
    "    a0 = train_data[0]\n",
    "    a1 = sigmoid(W1 @ a0 + b1)\n",
    "    a2 = sigmoid(W2 @ a1 + b2)\n",
    "    a3 = sigmoid(W3 @ a2 + b3)\n",
    "    \n",
    "    predicted_number = np.where(a3 == np.amax(a3))\n",
    "    real_number = np.where(train_data[1] == np.amax(train_data[1]))\n",
    "    \n",
    "    if predicted_number == real_number:\n",
    "        number_of_correct_estimations += 1\n",
    "\n",
    "print(f\"Accuracy: {number_of_correct_estimations / total_numbers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Backpropagation\n",
    "![Layers](assets/Layers.jpg)\n",
    "As we know, the learning process in a neural network is equivalent to minimize the cost function  \n",
    "$$Cost =\\sum_{j=0}^{n_{L} - 1} (a_{j}^{(L)} - y_{j})^2$$\n",
    "That is done with the help of Gradient Descent. To do that, we take a partial derivative of the cost function with respect to all the parameters to make the Gradient vector.\n",
    "$$(W, b) = (W, b) - \\alpha\\nabla Cost$$\n",
    "We take the derivatives with the help of backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 10\n",
    "learning_rate = 1\n",
    "number_of_epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use backpropagation?\n",
    "Regarding we have four layers (one input layer, one output layer, and two hidden layers), if we want to use backpropagation, at first, we have to define what we are dealing with.  \n",
    "Let us suppose we name our layers from 0 to 3, then we have:\n",
    "$$Cost =\\sum_{j=0}^{9} (a_{j}^{(L)} - y_{j})^2$$\n",
    "Each neuron at the last layer is equal to:\n",
    "$$a_{j}^{(3)} = \\sigma(z_{j}^{(3)})$$\n",
    "And $z_{j}^{(3)}$ is equal to:\n",
    "$$z_{j}^{(3)} = \\sum_{j=0}^{9} w_{jk}^{(3)}a_{k}^{(2)} + b_{j}^{(2)}$$\n",
    "### The last layer\n",
    "##### Weight\n",
    "If we apply the chain rule, we can reach to the following formula:  \n",
    "$$\\displaystyle \\frac{\\partial Cost}{\\partial w_{jk}^{(3)}} = \\displaystyle \\frac{\\partial Cost}{\\partial a_{j}^{(3)}} × \\displaystyle \\frac{\\partial a_{j}^{(3)}}{\\partial z_{j}^{(3)}} × \\displaystyle \\frac{\\partial z_{j}^{(3)}}{\\partial w_{jk}^{(3)}} $$\n",
    "\n",
    "$$\\displaystyle \\frac{\\partial Cost}{\\partial w_{jk}^{(3)}} = 2(a_{j}^{(3)} - y_{j}) × \\sigma^{'}(z_{j}^{(3)})×a_{k}^{(2)}$$\n",
    "\n",
    "##### Bias\n",
    "$$\\displaystyle \\frac{\\partial Cost}{\\partial b_{j}^{(3)}} = \\displaystyle \\frac{\\partial Cost}{\\partial a_{j}^{(3)}} × \\displaystyle \\frac{\\partial a_{j}^{(3)}}{\\partial z_{j}^{(3)}} × \\displaystyle \\frac{\\partial z_{j}^{(3)}}{\\partial b_{j}^{(3)}} $$\n",
    "\n",
    "$$\\displaystyle \\frac{\\partial Cost}{\\partial b_{j}^{(3)}} = 2(a_{j}^{(3)} - y_{j}) × \\sigma^{'}(z_{j}^{(3)})× 1$$\n",
    "\n",
    "##### Activation\n",
    "We also need to calculate partial derivatives with respect to the activation output of the previous layer. It helps us for backpropagation as we see further.  \n",
    "$$\\displaystyle \\frac{\\partial Cost}{\\partial a_{k}^{(2)}} = \\sum_{j=0}^{9} \\displaystyle \\frac{\\partial Cost}{\\partial a_{j}^{(3)}} × \\displaystyle \\frac{\\partial a_{j}^{(3)}}{\\partial z_{j}^{(3)}} × \\displaystyle \\frac{\\partial z_{j}^{(3)}}{\\partial a_{k}^{(2)}} $$\n",
    "\n",
    "$$\\displaystyle \\frac{\\partial Cost}{\\partial a_{k}^{(2)}} = \\sum_{j=0}^{9} (2(a_{j}^{(3)} - y_{j}) × \\sigma^{'}(z_{j}^{(3)})× w_{jk}^{(3)}) $$\n",
    "\n",
    "### 3rd layer\n",
    "##### Weight\n",
    "$$\\displaystyle \\frac{\\partial Cost}{\\partial w_{km}^{(2)}} = \\displaystyle \\frac{\\partial Cost}{\\partial a_{k}^{(2)}} × \\displaystyle \\frac{\\partial a_{k}^{(2)}}{\\partial z_{k}^{(2)}} × \\displaystyle \\frac{\\partial z_{k}^{(2)}}{\\partial w_{km}^{(2)}} $$\n",
    "\n",
    "$$\\displaystyle \\frac{\\partial Cost}{\\partial w_{km}^{(2)}} =  \\displaystyle \\frac{\\partial Cost}{\\partial a_{k}^{(2)}} × \\sigma^{'}(z_{k}^{(2)})×a_{m}^{(1)}$$\n",
    "\n",
    "##### Bias\n",
    "$$\\displaystyle \\frac{\\partial Cost}{\\partial b_{k}^{(2)}} = \\displaystyle \\frac{\\partial Cost}{\\partial a_{k}^{(2)}} × \\displaystyle \\frac{\\partial a_{k}^{(2)}}{\\partial z_{k}^{(2)}} × \\displaystyle \\frac{\\partial z_{k}^{(2)}}{\\partial b_{k}^{(2)}} $$\n",
    "\n",
    "$$\\displaystyle \\frac{\\partial Cost}{\\partial b_{k}^{(2)}} = \\displaystyle \\frac{\\partial Cost}{\\partial a_{k}^{(2)}} × \\sigma^{'}(z_{k}^{(2)})× 1$$\n",
    "\n",
    "##### Activation\n",
    "$$\\displaystyle \\frac{\\partial Cost}{\\partial a_{m}^{(1)}} = \\sum_{k=0}^{15} \\displaystyle \\frac{\\partial Cost}{\\partial a_{k}^{(2)}} × \\displaystyle \\frac{\\partial a_{k}^{(2)}}{\\partial z_{k}^{(2)}} × \\displaystyle \\frac{\\partial z_{k}^{(2)}}{\\partial a_{m}^{(1)}} $$\n",
    "\n",
    "$$\\displaystyle \\frac{\\partial Cost}{\\partial a_{m}^{(1)}} = \\sum_{k=0}^{15} (\\displaystyle \\frac{\\partial Cost}{\\partial a_{k}^{(2)}} × \\sigma^{'}(z_{k}^{(2)})× w_{km}^{(2)}) $$\n",
    "\n",
    "### 2nd layer\n",
    "##### Weight\n",
    "$$\\displaystyle \\frac{\\partial Cost}{\\partial w_{mv}^{(1)}} = \\displaystyle \\frac{\\partial Cost}{\\partial a_{m}^{(1)}} × \\displaystyle \\frac{\\partial a_{m}^{(1)}}{\\partial z_{m}^{(1)}} × \\displaystyle \\frac{\\partial z_{m}^{(1)}}{\\partial w_{mv}^{(1)}} $$\n",
    "\n",
    "$$\\displaystyle \\frac{\\partial Cost}{\\partial w_{mv}^{(1)}} =  \\displaystyle \\frac{\\partial Cost}{\\partial a_{m}^{(1)}} × \\sigma^{'}(z_{m}^{(1)})×a_{v}^{(0)}$$\n",
    "\n",
    "##### Bias\n",
    "$$\\displaystyle \\frac{\\partial Cost}{\\partial b_{m}^{(1)}} = \\displaystyle \\frac{\\partial Cost}{\\partial a_{m}^{(1)}} × \\displaystyle \\frac{\\partial a_{m}^{(1)}}{\\partial z_{m}^{(1)}} × \\displaystyle \\frac{\\partial z_{m}^{(1)}}{\\partial b_{m}^{(1)}} $$\n",
    "\n",
    "$$\\displaystyle \\frac{\\partial Cost}{\\partial b_{m}^{(1)}} = \\displaystyle \\frac{\\partial Cost}{\\partial a_{m}^{(1)}} × \\sigma^{'}(z_{m}^{(1)})× 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 58.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total_costs = []\n",
    "# Initialize W with random normal distribution for each layer.\n",
    "W1 = np.random.normal(size=(16, NUMBER_OF_PIXELS))\n",
    "W2 = np.random.normal(size=(16, 16))\n",
    "W3 = np.random.normal(size=(10, 16))\n",
    "\n",
    "# Initialize b = 0, for each layer.\n",
    "b1 = np.zeros((16, 1))\n",
    "b2 = np.zeros((16, 1))\n",
    "b3 = np.zeros((10, 1))\n",
    "\n",
    "for epoch in range(number_of_epochs):\n",
    "    batches = [train_set[x:x+batch_size] for x in range(0, 100, batch_size)]\n",
    "    for batch in batches:\n",
    "        # allocate grad_W matrix for each layer\n",
    "        grad_W1 = np.zeros((16, NUMBER_OF_PIXELS))\n",
    "        grad_W2 = np.zeros((16, 16))\n",
    "        grad_W3 = np.zeros((10, 16))\n",
    "        # allocate grad_b for each layer\n",
    "        grad_b1 = np.zeros((16, 1))\n",
    "        grad_b2 = np.zeros((16, 1))\n",
    "        grad_b3 = np.zeros((10, 1))\n",
    "        \n",
    "        for image, label in batch:\n",
    "            # compute the output (image is equal to a0)\n",
    "            a1 = sigmoid(W1 @ image + b1)\n",
    "            a2 = sigmoid(W2 @ a1 + b2)\n",
    "            a3 = sigmoid(W3 @ a2 + b3)\n",
    "            \n",
    "            # ---- Last layer\n",
    "            # weight\n",
    "            for j in range(grad_W3.shape[0]):\n",
    "                for k in range(grad_W3.shape[1]):\n",
    "                    grad_W3[j, k] += 2 * (a3[j, 0] - label[j, 0]) * a3[j, 0] * (1 - a3[j, 0]) * a2[k, 0]\n",
    "            \n",
    "            # bias\n",
    "            for j in range(grad_b3.shape[0]):\n",
    "                    grad_b3[j, 0] += 2 * (a3[j, 0] - label[j, 0]) * a3[j, 0] * (1 - a3[j, 0])\n",
    "            \n",
    "            # ---- 3rd layer\n",
    "            # activation\n",
    "            delta_3 = np.zeros((16, 1))\n",
    "            for k in range(16):\n",
    "                for j in range(10):\n",
    "                    delta_3[k, 0] += 2 * (a3[j, 0] - label[j, 0]) * a3[j, 0] * (1 - a3[j, 0]) * W3[j, k]\n",
    "            \n",
    "            # weight\n",
    "            for k in range(grad_W2.shape[0]):\n",
    "                for m in range(grad_W2.shape[1]):\n",
    "                    grad_W2[k, m] += delta_3[k, 0] * a2[k,0] * (1 - a2[k, 0]) * a1[m, 0]\n",
    "            \n",
    "            # bias\n",
    "            for k in range(grad_b2.shape[0]):\n",
    "                    grad_b2[k, 0] += delta_3[k, 0] * a2[k, 0] * (1 - a2[k, 0])\n",
    "                    \n",
    "            # ---- 2nd layer\n",
    "            # activation\n",
    "            delta_2 = np.zeros((16, 1))\n",
    "            for m in range(16):\n",
    "                for k in range(16):\n",
    "                    delta_2[m, 0] += delta_3[k, 0] * a2[k, 0] * (1 - a2[k, 0]) * W2[k, m]\n",
    "            \n",
    "            # weight\n",
    "            for m in range(grad_W1.shape[0]):\n",
    "                for v in range(grad_W1.shape[1]):\n",
    "                    grad_W1[m, v] += delta_2[m, 0] * a1[m,0] * (1 - a1[m, 0]) * image[v, 0]\n",
    "                    \n",
    "            # bias\n",
    "            for m in range(grad_b1.shape[0]):\n",
    "                    grad_b1[m, 0] += delta_2[m, 0] * a1[m, 0] * (1 - a1[m, 0])\n",
    "        \n",
    "        W3 = W3 - (learning_rate * (grad_W3 / batch_size))\n",
    "        W2 = W2 - (learning_rate * (grad_W2 / batch_size))\n",
    "        W1 = W1 - (learning_rate * (grad_W1 / batch_size))\n",
    "        \n",
    "        b3 = b3 - (learning_rate * (grad_b3 / batch_size))\n",
    "        b2 = b2 - (learning_rate * (grad_b2 / batch_size))\n",
    "        b1 = b1 - (learning_rate * (grad_b1 / batch_size))\n",
    "    \n",
    "    # calculate cost average per epoch\n",
    "    cost = 0\n",
    "    for train_data in train_set[:100]:\n",
    "        a0 = train_data[0]\n",
    "        a1 = sigmoid(W1 @ a0 + b1)\n",
    "        a2 = sigmoid(W2 @ a1 + b2)\n",
    "        a3 = sigmoid(W3 @ a2 + b3)\n",
    "\n",
    "        for j in range(10):\n",
    "            cost += np.power((a3[j, 0] - train_data[1][j,  0]), 2)\n",
    "            \n",
    "    cost /= 100\n",
    "    total_costs.append(cost)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUZf7+8fcnjRCkE4p0KdJZMPQQQHQJRRArYAEboqAguK7bXHddd9dd6SiIFLssCkpRmigJRUqCtNAMRQkoUqQoIMXn90eG7y/GBAZIciaT+3VduZiZ8yRzexxuTk55jjnnEBGR/C/E6wAiIpIzVOgiIkFChS4iEiRU6CIiQUKFLiISJMK8euMyZcq4atWqefX2IiL5UnJy8kHnXHRWyzwr9GrVqpGUlOTV24uI5Etm9lV2y7TLRUQkSKjQRUSChApdRCRIqNBFRIKECl1EJEj4VehmFm9m28ws1cyezmJ5STP7wMw2mNlqM2uQ81FFRORCLlroZhYKvAR0BuoBvc2sXqZhfwTWOecaAfcCo3M6qIiIXJg/W+jNgVTn3E7n3GlgGtAj05h6wGIA59xWoJqZlcvRpD6HfviJv81J4dSZc7nx40VE8i1/Cr0isCfD8zTfaxmtB24BMLPmQFWgUuYfZGb9zSzJzJIOHDhwWYFX7DjEayt2c/ekVRw5cfqyfoaISDDyp9Ati9cy3xXj30BJM1sHPAZ8AZz91Tc5N9E5F+Oci4mOzvLK1Yu6qfHVjO3dhA1pR7ltwufsPXLysn6OiEiw8afQ04DKGZ5XAvZlHOCcO+acu8859xvS96FHA7tyLGUm3Rpdzev3N2f/0VPc+vIKtn17PLfeSkQk3/Cn0NcAtcysuplFAL2A2RkHmFkJ3zKAB4FE59yxnI36S61qlGb6gFY4HLdNWMHKnYdy8+1ERALeRQvdOXcWGAQsALYA051zKWY2wMwG+IbVBVLMbCvpZ8MMzq3AGdWtUIyZj7ahXLFI7p28mo83fpMXbysiEpDMq5tEx8TEuJyabfHIidM88HoSa7/+nmdvqk/f1tVy5OeKiAQaM0t2zsVktSworhQtERXB2w+24Ia65fjr7BRemL8Vr/6hEhHxSlAUOkBkeCjj72pKnxZVGL9kB8PeW8+Zcz97HUtEJM94doOL3BAWGsLzNzegfLFIRizazsEfTjP+rqYUKRRU/5kiIlkKmi3088yMxzvW4t+3NGR56kF6v7qSgz/85HUsEZFcF3SFfl6v5lWYeM91bN9/nFvHr+CrQz96HUlEJFcFbaEDdKxbjnceasmxk2e45eUVbEg74nUkEZFcE9SFDtC0Sknef6Q1hSNC6TVxJQnbL28OGRGRQBf0hQ5QI/oqZj7Smqqli/DAa2uYkZzmdSQRkRxXIAodoGyxSKY/3JIW15Ri2HvrGTp9HYd0sFREgkiBKXSAopHhTO3XnEEdajJ73T5uGJHAe0l7dBGSiASFAlXoABFhITzZ6Vo+HtyWa6Kv4nfvb6DPq6vYeeAHr6OJiFyRAlfo59UuV5T3Hm7F8z0bsGnfUeJHLWX0J1/y01ndCUlE8qcCW+gAISHGXS2qsnhoO26sX46Rn2yn65hlrN512OtoIiKXrEAX+nlli0XyUp+mTO3XjJOnz3HHK5/z9IwNHD1xxutoIiJ+U6Fn0KFOWRYNjaN/3DW8l5xGxxFLmLVurw6aiki+oELPJCoijD92qcvsQW24ukRhBk9bR9+pa9hz+ITX0URELkiFno36Vxfng0fb8Neb6pG8+zA3jkxg/JIdmpJXRAKWCv0CQkOM+9pUZ9HQdrStFc0L87dy09hlfPH1915HExH5FRW6H64uUZhX741hwt3XceTEGW4Zv4K/fLiJY6d00FREAocK/RLENyjPoqFx9G1VjbdXfUXH4QnMWb9PB01FJCCo0C9R0chwnu1enw8HtqFcsUI89u4X9J26hq8P6aCpiHhLhX6ZGlUqwayBsfz1pnqs/ep7bhyZwEufpXL6rA6aiog3VOhX4PxB00+GtuP6OmX574JtdB2zVFeaiognVOg5oHzxSMbffR1T+sVwwnel6VPvr+f7H097HU1EChAVeg66vk45Fg2N4+F21zBj7V46jkjg/eQ0HTQVkTyhQs9hURFh/KFzXT56PJZqpaN48r319H51JanfaXpeEcldKvRcUqd8Md4f0Jp/9mzI5n3H6Dw6kRELt3HqjKbnFZHcoULPRSEhRp8WVVg8rD1dG1ZgzKepxI9KZNmXB72OJiJBSIWeB6KLFmJUrya89UALzIy7J6/isXe/YP+xU15HE5EgokLPQ7G1yjBvcFuG3FCLBSnf0nF4AlOW7eKsJvwSkRzgV6GbWbyZbTOzVDN7Oovlxc1sjpmtN7MUM7sv56MGh8jwUIbcUJtFT8RxXdWS/H3uZm4at5zkr3TuuohcmYsWupmFAi8BnYF6QG8zq5dp2EBgs3OuMdAeGG5mETmcNahULV2E1+5rxoS7m3LkxGluHf85v39/A4d17rqIXCZ/ttCbA6nOuZ3OudPANKBHpjEOKGpmBlwFHAbO5mjSIGRmxDeowCdD2/nOXU/j+uFLeHf11/z8s85dF5FL40+hVwT2ZHie5nsto3FAXWAfsBEY7Jz71Y5hM+tvZklmlnTgwIHLjBx8ihRKP3f948FtqV2uKH+YuZFbxq9g096jXkcTkXzEn0K3LF7LvPnYCVgHXA38BhhnZsV+9U3OTXTOxTjnYqKjoy85bLCrXa4o/+vfkhF3NCbt+xN0H7eMZ2enaN51EfGLP4WeBlTO8LwS6VviGd0HzHTpUoFdQJ2ciViwmBm3NK3E4mHtubtlVV7/fDfXv5jAh1/oZtUicmH+FPoaoJaZVfcd6OwFzM405mugI4CZlQOuBXbmZNCCpnjhcP7eowGzB8ZSsUQkQ/63zjeFwHGvo4lIgLpooTvnzgKDgAXAFmC6cy7FzAaY2QDfsOeA1ma2EVgM/N45p8shc0DDSsWZ+Wgbnu/ZgC3fHCd+1FL+PW8rJ07rmLOI/JJ59Wt8TEyMS0pK8uS986tDP/zEv+dt5b3kNCoUj+SPXerSrVEF0k8uEpGCwMySnXMxWS3TlaL5SOmrCvHf2xsz45FWlCoSwWPvfkHvV1ey7VvthhERFXq+dF3VUsweFMvzPRuw9dvjdBmzlL/NSeHoSZ0NI1KQqdDzqdAQ464WVflsWHt6N6/Mayt2c/2LS5i+Zo8uShIpoFTo+VzJIhH84+aGzBkUS7UyRXhqxgZ6jl/B+j1HvI4mInlMhR4kGlQszvsDWjHijsbsO3KSm19eztMzNnDoh5+8jiYieUSFHkTOX5T06bB2PBhbnfeT0+jw4hJeX7FbU/SKFAAq9CBUNDKcP3Wtx/whbWlUqQR/nZ1Ct7HLWLXzkNfRRCQXqdCDWM2yRXnzgeZMuLspx0+d5c6JK3n83S/49qjulCQSjFToQS7jFL2Pd6zF/JRvuX74EsYv2cHps9oNIxJMVOgFROGIUIbeWJtPnmhH6xpleGH+VuJHJ7L0S01jLBIsVOgFTJXSUUzqG8PUfs0497PjnsmreeStZPYeOel1NBG5QmFeBxBvdKhTllY1SjNp6U7GfZbKZ9u+Y1CHmjwUdw2FwkK9jicil0Fb6AVYZHgog66vxSdD29Hh2rK8uHA7nUYm8tm277yOJiKXQYUuVCoZxfi7r+ON+5sTEmLcN3UND72RxJ7DJ7yOJiKXQIUu/yeudjTzB8fx+/g6LE89yA0jEhj1yXZOnTnndTQR8YMKXX4hIiyER9rXYPGwdtxYrxyjPvmSG0cm8Mnm/V5HE5GLUKFLlioUL8y4Pk1558EWRIaF8uAbSdz/2hp2H/zR62gikg0VulxQ65pl+HhwW/7ctS6rdx3mtyMTGb5wGydPazeMSKBRoctFhYeG8GDba/h0WDu6NCzP2E9T+e2oBJbobBiRgKJCF7+VLRbJqF5NePehloSHhtBv6hoGvbOW745pbhiRQKBCl0vWqkZp5g1uy9Aba7Nw8346Dk/gzc93c053ShLxlApdLkuhsFAe71iLBUPiaFS5OH+ZlcIt41eQsu+o19FECiwVulyR6mWK8NYDLRh152/Y+/0Juo9bzj/mbubHn856HU2kwFGhyxUzM25uUpHFQ9tzR0xlJi3bxY0jElikc9dF8pQKXXJM8ahw/nVLQ94f0IqikeE89EYS/d9IYp9mchTJEyp0yXEx1Uox9/FYfh9fh8QvD3DjiAQmLd2p+5qK5DIVuuSK8ND0KQQWPdGO5tVL8Y+PttDjpeWs33PE62giQUuFLrmqcqkopvRrxst3NeXA8Z+4+eXlPDNrE8dPnfE6mkjQUaFLrjMzujSswCfD2nFvy6q8ufIrOo1M1JWmIjlMhS55plhkOH/r0YAZj7QmqlAY/aauYdj09Rw5cdrraCJBQYUuea5plZLMfSyWgR1q8OG6vdw4MpH5m771OpZIvudXoZtZvJltM7NUM3s6i+W/M7N1vq9NZnbOzErlfFwJFpHhofyuUx1mDWxDmasKMeCtZAa+s5aDP/zkdTSRfMucu/D8G2YWCmwHbgTSgDVAb+fc5mzG3wQ84Zy7/kI/NyYmxiUlJV1WaAkuZ879zCsJOxizOJUihUJ5tnt9uje+GjPzOppIwDGzZOdcTFbL/NlCbw6kOud2OudOA9OAHhcY3xt499JjSkEVHhrCoOtrMffxWKqULsLgaet46I1k9msWR5FL4k+hVwT2ZHie5nvtV8wsCogHZmSzvL+ZJZlZ0oEDBy41qwS52uWKMvOR1vy5a12WfnmAG0YkMH3NHi72W6SIpPOn0LP6vTe7v2E3Acudc4ezWuicm+ici3HOxURHR/ubUQqQ0BDjwbbXMH9IHHUrFOOpGRu4d8pq0r4/4XU0kYDnT6GnAZUzPK8E7MtmbC+0u0VyQPUyRZj2UEue61GftV99T6eRibzx+W5+1pzrItnyp9DXALXMrLqZRZBe2rMzDzKz4kA7YFbORpSCKiTEuKdVNRY8EUfTqiV5ZlYKvSauZJduVC2SpYsWunPuLDAIWABsAaY751LMbICZDcgwtCew0Dmnv22SoyqVjOKN+5vzn9saseXbY8SPSmTKsl3aWhfJ5KKnLeYWnbYol2P/sVP8YeZGPt36Ha2uKc2LdzSmYonCXscSyTNXetqiSMAoVyySyX1jeOHWhmxIO0L8yETeT07TmTAiqNAlHzIz7mxWhXmD08+EefK99Tz8ZrKuMpUCT4Uu+VaV0lG8278lf+xShyXbDhA/KpGFKZoTRgouFbrka6EhRv+4Gsx5LJayRSPp/2Yyv3tvveZblwJJhS5B4dryRflwYBsGdajJjLVpxI9ayuc7DnkdSyRPqdAlaESEhfBkp2t5/5HWRISF0PvVlTw3dzOnzpzzOppInlChS9BpWqUkHz0ey72tqjJ52S5uGruMjWlHvY4lkutU6BKUoiLC+HuPBrxxf3OOnzpLz5eXM2bxl5w997PX0URyjQpdglpc7WgWDImja6MKjFi0nVsnfM6OAz94HUskV6jQJegVjwpndK8mvNSnKV8d+pGuY5by5ue7dTGSBB0VuhQYXRtVYOGQOFpUL81fZqXwwOtJuhhJgooKXQqUssUiee2+Zjx7Uz2WpR4kflQin237zutYIjlChS4FjpnRr0115gyKpcxVhbhv6hqenZ2i0xsl31OhS4F1/mKkB2Kr89qK3XQft4wt3xzzOpbIZVOhS4EWGR7KX7rV4/X7m/P9iTP0GLecyZprXfIpFboI0K52NPMHtyWudjTPzd1M36mr+e7YKa9jiVwSFbqIT+mrCvHqvdfxfM8GrNl9mE6avVHyGRW6SAZmxl0tqjL3sbZULFmY/m8m84eZGzlx+qzX0UQuSoUukoWaZa9i5iNtGNCuBtPWfE23MZoPRgKfCl0kGxFhITzduQ5vP9iCE6fP0fPl5YxfsoNzOmAqAUqFLnIRrWuUYf6Qtvy2fjlemL+VuyatZN+Rk17HEvkVFbqIH0pERfBSn6b897ZGbEw7SufRS5m38RuvY4n8ggpdxE9mxu0xlfno8bZUKx3FI2+v5ffvb9ABUwkYKnSRS1StTBHef6Q1j7avwfTkPTpgKgFDhS5yGcJDQ3gqvg7vPNiSk2fOccv45UxI2KErTMVTKnSRK9CqRmnmDW7LDXXL8e95W7lnyiq+PaorTMUbKnSRK1QiKoKX72rKC7c2ZO1XR4gfncgCXWEqHlChi+QAM+POZlWY+3gslUoW5uE3k/njBxs5eVpT8kreUaGL5KAa0elXmD4cdw3vrPqabmOXkrJPB0wlb6jQRXJYRFgIf+hSl7ceaMHxU2fp+dIKJi3dqQOmkuv8KnQzizezbWaWamZPZzOmvZmtM7MUM0vI2Zgi+U9srTLMHxJHu2uj+cdHWzQlr+S6ixa6mYUCLwGdgXpAbzOrl2lMCeBloLtzrj5wey5kFcl3ShWJYOI91/GPm9On5I0fvZTFW/Z7HUuClD9b6M2BVOfcTufcaWAa0CPTmD7ATOfc1wDOOd11V8THzLi7ZVXmDIqlXLFIHng9iT9/qAOmkvP8KfSKwJ4Mz9N8r2VUGyhpZkvMLNnM7s3qB5lZfzNLMrOkAwcOXF5ikXyqVrmifDiwNQ/GVuetlV/TdexSXWEqOcqfQrcsXst8dCcMuA7oCnQC/mJmtX/1Tc5NdM7FOOdioqOjLzmsSH5XKCyUP3erlz4l70/pU/K+9FmqpuSVHOFPoacBlTM8rwTsy2LMfOfcj865g0Ai0DhnIooEnzY106fk7VS/PP9dsI3eE1ey5/AJr2NJPudPoa8BaplZdTOLAHoBszONmQW0NbMwM4sCWgBbcjaqSHApERXBuD5NGH57YzZ/c4wuo5fywRdpOKetdbk8Fy1059xZYBCwgPSSnu6cSzGzAWY2wDdmCzAf2ACsBiY55zblXmyR4GBm3HpdJeYNbsu15YvyxP/W89i7X3D0xBmvo0k+ZF5tDcTExLikpCRP3lskEJ372TEhYQcjF20numghht/RmNY1yngdSwKMmSU752KyWqYrRUUCRGiIMbBDTWY+2prC4aHcNWkV//x4Cz+d1emN4h8VukiAaVSpBHMfj6VP8ypMTNxJj3HL2b7/uNexJB9QoYsEoKiIMJ7v2ZDJfWM4cPwnuo1dxtTluzQfjFyQCl0kgHWsW475Q+JoW7MMf5uzmb5TV7Nf88FINlToIgEuumghJvWN4fme6fPBdBqVyMcbv/E6lgQgFbpIPmBm3NWiKh893pYqpaJ49O21DJmm0xvll1ToIvlIjeirmPFIa564oTZzN3xDp1GJJGzXvEiSToUuks+Eh4Yw+IZafPBoG4pGhtF3ymr+9MFGfvzprNfRxGMqdJF8qmGl4sx5LJaH2lbnndVf02XMUpJ2H/Y6lnhIhS6Sj0WGh/KnrvWY9lBLfnaO21/5nH/N08VIBZUKXSQItLimNPMGx9GrWRVeSdhJ97HLdXPqAkiFLhIkrioUxr9uacjUfs34/sRpeoxbzrhPv+TsuZ+9jiZ5RIUuEmQ61CnLwifi6NywAi8u3M5tEz5nx4EfvI4leUCFLhKESkRFMLZ3E8b1acLuQz/SdcxSTR1QAKjQRYJYt0ZXs3BIHK2uKc3f5mzm7smr2HvkpNexJJeo0EWCXNlikUzp14x/39KQ9XuOED8ykelr9ujOSEFIhS5SAJgZvZpXYf6QOOpXLMZTMzbQd+oaba0HGRW6SAFSuVQU7zzYkud61Cdp92E6jUzknVVfa2s9SKjQRQqYkBDjnlbVWDAkjkaVivPHDzZy9+RV7Dl8wutocoVU6CIFVOVSUbz9YAv+2bMh6/ccpdOoRN78fLfOhMnHVOgiBZiZ0adFFRY8Ecd1VUvyl1kp9Jm0kq8O/eh1NLkMKnQRoWKJwrxxf3P+c2sjUvYeI37UUl7Teev5jgpdRID0rfU7mlVm4dA4WlxTimfnbKbXxJXsOqit9fxChS4iv1CheGGm9mvGi7c3Zuu3x+g8OpFJS3dyTlvrAU+FLiK/Ymbcdl0lFg1tR5saZfjHR1u4fcIKzQkT4FToIpKtcsUimdQ3hpF3NmbHgR/pPHopryTs0AyOAUqFLiIXZGb0bFKJRUPjaF87mn/N20rPl1dovvUApEIXEb+ULRrJK/dcx7g+Tfjm6Em6j1vOv+Zt4eRp3R0pUKjQRcRvZka3RlfzydB23Nq0Iq8k7CR+dCLLUw96HU1QoYvIZSgRFcF/bmvMOw+1wIC7Jq1i2PT1fP/jaa+jFWh+FbqZxZvZNjNLNbOns1je3syOmtk639czOR9VRAJN6xplmD8kjkfb12DWur3cMCKBWev2arIvj1y00M0sFHgJ6AzUA3qbWb0shi51zv3G9/X3HM4pIgEqMjyUp+LrMOexWCqVLMzgaeu477U1pH2vyb7ymj9b6M2BVOfcTufcaWAa0CN3Y4lIflO3QjFmPtqGZ7rVY/Wuw/x2ZCKTl+3SBUl5yJ9CrwjsyfA8zfdaZq3MbL2ZzTOz+ln9IDPrb2ZJZpZ04MCBy4grIoEsNMS4P7Y6C5+Io0X1Ujw3dzO3vLyczfuOeR2tQPCn0C2L1zL/k7sWqOqcawyMBT7M6gc55yY652KcczHR0dGXllRE8o1KJaOY0q8ZY3s3Ye+Rk9w0bhkvzN/KqTM6xTE3+VPoaUDlDM8rAfsyDnDOHXPO/eB7/DEQbmZlciyliOQ7ZsZNjf//KY7jl+yg0yid4pib/Cn0NUAtM6tuZhFAL2B2xgFmVt7MzPe4ue/nHsrpsCKS/2R1iuPQ6es4+MNPXkcLOhctdOfcWWAQsADYAkx3zqWY2QAzG+AbdhuwyczWA2OAXk7nLYlIBudPcRzYoQZz1u+j4/AE3l71leZcz0HmVe/GxMS4pKQkT95bRLyV+t1x/vzhJlbuPEzjyiV4/uYGNKhY3OtY+YKZJTvnYrJapitFRSTP1SxblHcfasnIOxuz9/sTdB+3jGdnp3D81Bmvo+VrKnQR8cT5WRwXD23PXS2q8vrnu+k4PIE56/fpStPLpEIXEU8VjwrnuZsb8OGjbShbrBCPvfsF905ZrVvfXQYVuogEhMaVSzBrYCx/616fdV8fodOoREYu2q5z1y+BCl1EAkZoiNG3dTUWD2tHfP3yjF78JZ1GJZKwXVeW+0OFLiIBp2yxSMb0bsJbD7Qg1Iy+U1Yz8O21fHv0lNfRApoKXUQCVmytMswb0pZhN9bmky376Th8CZOX7dI9TbOhQheRgFYoLJTHOtZi0RPtaOab8Kvb2GWs2qmL0TNToYtIvlCldBRT+zVjwt1NOX7qLHdOXMnj736h3TAZqNBFJN8wM+IbVOCToe14vGMt5qd8y/XDl/DyklR+OquzYVToIpLvFI4IZeiNtVk8tB2xNcvwn/nbiB+1lM+2fed1NE+p0EUk36pcKoqJ98bw+v3NMeC+qWt48PU1fHWoYF6UpEIXkXyvXe1o5g+J4w+d6/D5jkPcODKR4Qu3cfJ0wdoNo0IXkaAQERbCw+1q8OmT7enSoDxjP02l4/AlfLzxmwIzN4wKXUSCSrlikYzq1YTpD7eiWOFwHn17LXdNWsWX+497HS3XqdBFJCg1r16KuY/F8vce9dm09yidRy/lubmbORbEU/Sq0EUkaIWFhnBvq2p89mR7bo+pxJTlu7j+xQSmJ+0JyjslqdBFJOiVvqoQ/7qlEbMGtqFyqcI89f4Gur8UfFebqtBFpMBoVKkEMx9pzehev+HwD6e5c+JKHnkrma8PnfA6Wo4I8zqAiEheMjN6/KYiv61XnklLd/Lykh0s3vId98VWY1CHmhSNDPc64mXTFrqIFEiFI9In/frsyfbc1PhqXknYSYcXl/Du6q85l0/3r6vQRaRAK188kuF3NGb2oDZUK12EP8zcSNcxS1mRetDraJdMhS4iQvr+9fcGtGJcnyYcP3WWPpNW8dAbSfnq3qYqdBERHzOjW6OrWTysHb/rdC0rUg/y25EJPP/RZo6eDPzz11XoIiKZRIaHMrBDTT57sj09m1Rk0rJddHhxCW+u/Cqg75akQhcRyUbZYpH857bGzBkUS82yV/GXDzfRZcxSlmz7LiDnh1Ghi4hcRIOKxflf/5ZMuLspp878TL+pa7h78io27T3qdbRfUKGLiPjh/N2SFg2N45lu9di87xjdxi5jyLQv2HM4MC5MMq9+bYiJiXFJSUmevLeIyJU6duoME5bsYPKyXTgH97aqyqDra1IiKiJX39fMkp1zMVkuU6GLiFy+b46eZOSi7byXnEbRQmEM7FCTvq2rERkemivvd6FC92uXi5nFm9k2M0s1s6cvMK6ZmZ0zs9suN6yISH5SoXhh/nNbY+YNbst1VUvyr3lbuf7FJcxITsvzK04vWuhmFgq8BHQG6gG9zaxeNuNeABbkdEgRkUBXp3wxpt7XnHceakGZooUY9t56uo5ZSsL2A3l2Row/W+jNgVTn3E7n3GlgGtAji3GPATOAgn3bbREp0FrXKMOHj7ZhTO8m/Hj6LH2nrOaeyavz5IwYfwq9IrAnw/M032v/x8wqAj2BCTkXTUQkfwoJMbo3vppPhrbjmW71SNl3NE/OiPGn0C2L1zL//jAK+L1z7oK32Daz/maWZGZJBw4c8DejiEi+VCgslPtjq5PwVAcebV+DeZu+pePwBCYt3Zkr7+fPfOhpQOUMzysB+zKNiQGmmRlAGaCLmZ11zn2YcZBzbiIwEdLPcrnc0CIi+UmxyHCeiq/DPa2qMmLhdiqXisqV9/Gn0NcAtcysOrAX6AX0yTjAOVf9/GMzew2Ym7nMRUQKugrFC/Pf2xvn2s+/aKE7586a2SDSz14JBaY451LMbIBvufabi4gEAL9uQeec+xj4ONNrWRa5c67flccSEZFLpblcRESChApdRCRIqNBFRIKECl1EJEio0EVEgoQKXUQkSHg2H7qZHQC+usxvLwMczME4OS3Q80HgZ1S+K6N8VyaQ81V1zkVntcCzQr8SZpaU3QTvgSDQ80HgZ1S+K6N8VybQ82VHu1xERIKECl1EJEjk10Kf6HWAiwj0fBD4GZXvyijflQn0fFuQAjMAAARiSURBVFnKl/vQRUTk1/LrFrqIiGSiQhcRCRIBXehmFm9m28ws1cyezmK5mdkY3/INZtY0D7NVNrPPzGyLmaWY2eAsxrQ3s6Nmts739Uxe5fO9/24z2+h776Qslnu5/q7NsF7WmdkxMxuSaUyerz8zm2Jm35nZpgyvlTKzRWb2pe/Pktl87wU/r7mY779mttX3//ADMyuRzfde8POQi/meNbO9Gf4/dsnme71af//LkG23ma3L5ntzff1dMedcQH6RfjONHcA1QASwHqiXaUwXYB7p9z1tCazKw3wVgKa+x0WB7Vnka0/63Zu8Woe7gTIXWO7Z+svi//W3pF8w4en6A+KApsCmDK/9B3ja9/hp4IVs/hsu+HnNxXy/BcJ8j1/IKp8/n4dczPcs8KQfnwFP1l+m5cOBZ7xaf1f6Fchb6M2BVOfcTufcaWAa0CPTmB7AGy7dSqCEmVXIi3DOuW+cc2t9j48DW4CKefHeOciz9ZdJR2CHc+5yrxzOMc65ROBwppd7AK/7Hr8O3JzFt/rzec2VfM65hc65s76nK0m/768nsll//vBs/Z1n6TdFvgN4N6ffN68EcqFXBPZkeJ7GrwvTnzG5zsyqAU2AVVksbmVm681snpnVz9Ng4ICFZpZsZv2zWB4Q64/0+9Rm95fIy/V3Xjnn3DeQ/g85UDaLMYGyLu8n/beurFzs85CbBvl2CU3JZpdVIKy/tsB+59yX2Sz3cv35JZAL3bJ4LfM5lv6MyVVmdhUwAxjinDuWafFa0ncjNAbGAnl94+w2zrmmQGdgoJnFZVoeCOsvAugOvJfFYq/X36UIhHX5J+As8HY2Qy72ecgt44EawG+Ab0jfrZGZ5+sP6M2Ft869Wn9+C+RCTwMqZ3heCdh3GWNyjZmFk17mbzvnZmZe7pw75pz7wff4YyDczMrkVT7n3D7fn98BH5D+a21Gnq4/n87AWufc/swLvF5/Gew/vyvK9+d3WYzx+rPYF+gG3OV8O3wz8+PzkCucc/udc+eccz8Dr2bzvl6vvzDgFuB/2Y3xav1dikAu9DVALTOr7tuK6wXMzjRmNnCv72yNlsDR878a5zbf/rbJwBbn3IhsxpT3jcPMmpO+vg/lUb4iZlb0/GPSD5xtyjTMs/WXQbZbRV6uv0xmA319j/sCs7IY48/nNVeYWTzwe6C7c+5ENmP8+TzkVr6Mx2V6ZvO+nq0/nxuArc65tKwWern+LonXR2Uv9EX6WRjbST/6/SffawOAAb7HBrzkW74RiMnDbLGk/0q4AVjn++qSKd8gIIX0I/YrgdZ5mO8a3/uu92UIqPXne/8o0gu6eIbXPF1/pP/j8g1whvStxgeA0sBi4Evfn6V8Y68GPr7Q5zWP8qWSvv/5/OdwQuZ82X0e8ijfm77P1wbSS7pCIK0/3+uvnf/cZRib5+vvSr906b+ISJAI5F0uIiJyCVToIiJBQoUuIhIkVOgiIkFChS4iEiRU6CIiQUKFLiISJP4f+XDv5HNdON4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_size = [x for x in range(20)]\n",
    "plt.plot(epoch_size, total_costs)\n",
    "\n",
    "for train_data in train_set[:100]:\n",
    "    a0 = train_data[0]\n",
    "    a1 = sigmoid(W1 @ a0 + b1)\n",
    "    a2 = sigmoid(W2 @ a1 + b2)\n",
    "    a3 = sigmoid(W3 @ a2 + b3)\n",
    "    \n",
    "    predicted_number = np.where(a3 == np.amax(a3))\n",
    "    real_number = np.where(train_data[1] == np.amax(train_data[1]))\n",
    "    \n",
    "    if predicted_number == real_number:\n",
    "        number_of_correct_estimations += 1\n",
    "        \n",
    "print(f\"Accuracy: {number_of_correct_estimations / 100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Vectorization\n",
    "Because of the long execution time, we've only dealt on 100 first pictures so far. We use vectorization to solve this problem. It implies that we use matrix operations instead of for loops to measure each entry of matrices separately.\n",
    "\n",
    "As a result, the processing time would be significantly reduced. The explanation for this is that matrix operations can run in parallel on multi-core CPUs. Furthermore, today's processors have instructions for working with large vector data, which will be much more effective.\n",
    "\n",
    "We have implemented the second section (Feedforward) in a vectorized way. Now we're attempting to do the same thing with backpropagation.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In vectorized notiation, we have:\n",
    "$$Cost =(\\overrightarrow{a}^{(3)} - \\overrightarrow{y})^{T}(\\overrightarrow{a}^{(3)} - \\overrightarrow{y})$$\n",
    "The activation vector at the last layer is equal to:\n",
    "$$\\overrightarrow{a}^{(3)} = \\sigma(\\overrightarrow{z}^{(3)})$$\n",
    "And $\\overrightarrow{z}^{(3)}$ is equal to:\n",
    "$$\\overrightarrow{z}^{(3)} = W^{(3)}\\overrightarrow{a}^{(2)} + \\overrightarrow{b}^{(2)}$$\n",
    "### The last layer\n",
    "##### Weight\n",
    "$$\\displaystyle \\frac{\\partial Cost}{\\partial W^{(3)}} = 2(\\overrightarrow{a}^{(3)} - \\overrightarrow{y})\\overrightarrow{a}^{(3)}(1 - \\overrightarrow{a}^{(3)}) \\bullet \\overrightarrow{a}^{(2)}$$\n",
    "##### Bias\n",
    "$$\\displaystyle \\frac{\\partial Cost}{\\partial \\overrightarrow{b}^{(3)}} = 2 (\\overrightarrow{a}^{(3)} - \\overrightarrow{y}) \\overrightarrow{a}^{(3)}(1 - \\overrightarrow{a}^{(3)})$$\n",
    "##### Activation\n",
    "$$\\displaystyle \\frac{\\partial Cost}{\\partial \\overrightarrow{a}^{(2)}} = {W_{3}^{T}} (2(\\overrightarrow{a}^{(3)} - \\overrightarrow{y}) \\overrightarrow{a}^{(3)}(1 - \\overrightarrow{a}^{(3)})) $$\n",
    "\n",
    "### 3rd Layer\n",
    "##### Weight\n",
    "$$\\displaystyle \\frac{\\partial Cost}{\\partial W^{(2)}} = \\displaystyle \\frac{\\partial Cost}{\\partial \\overrightarrow{a}^{(2)}}\\overrightarrow{a}^{(2)}(1 - \\overrightarrow{a}^{(2)}) \\bullet \\overrightarrow{a}^{(1)}$$\n",
    "##### Bias\n",
    "$$\\displaystyle \\frac{\\partial Cost}{\\partial \\overrightarrow{b}^{(2)}} = (\\displaystyle \\frac{\\partial Cost}{\\partial \\overrightarrow{a}^{(2)}})\\overrightarrow{a}^{(2)}(1 - \\overrightarrow{a}^{(2)})$$\n",
    "##### Activation \n",
    "$$\\displaystyle \\frac{\\partial Cost}{\\partial \\overrightarrow{a}^{(1)}} = {W_{2}^{T}} (\\displaystyle \\frac{\\partial Cost}{\\partial \\overrightarrow{a}^{(2)}}) \\overrightarrow{a}^{(2)}(1 - \\overrightarrow{a}^{(2)})) $$\n",
    "\n",
    "### 2nd\n",
    "##### Weight\n",
    "$$\\displaystyle \\frac{\\partial Cost}{\\partial W^{(1)}} = \\displaystyle \\frac{\\partial Cost}{\\partial \\overrightarrow{a}^{(1)}}\\overrightarrow{a}^{(1)}(1 - \\overrightarrow{a}^{(1)}) \\bullet \\overrightarrow{a}^{(0)}$$\n",
    "##### Bias\n",
    "$$\\displaystyle \\frac{\\partial Cost}{\\partial \\overrightarrow{b}^{(1)}} = (\\displaystyle \\frac{\\partial Cost}{\\partial \\overrightarrow{a}^{(1)}})\\overrightarrow{a}^{(1)}(1 - \\overrightarrow{a}^{(1)})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 570 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Allocate W matrix and vector b for each layer.\n",
    "\n",
    "# Initialize W with random normal distribution for each layer. \n",
    "W1 = np.random.normal(size=(16, NUMBER_OF_PIXELS))\n",
    "W2 = np.random.normal(size=(16, 16))\n",
    "W3 = np.random.normal(size=(10, 16))\n",
    "\n",
    "# Initialize b = 0, for each layer.\n",
    "b1 = np.zeros((16, 1))\n",
    "b2 = np.zeros((16, 1))\n",
    "b3 = np.zeros((10, 1))\n",
    "\n",
    "total_costs = []\n",
    "batches = [train_set[x:x+batch_size] for x in range(0, 100, batch_size)]\n",
    "for epoch in range(number_of_epochs):\n",
    "    for batch in batches:\n",
    "        # allocate grad_W matrix for each layer\n",
    "        grad_W1 = np.zeros((16, NUMBER_OF_PIXELS))\n",
    "        grad_W2 = np.zeros((16, 16))\n",
    "        grad_W3 = np.zeros((10, 16))\n",
    "        # allocate grad_b for each layer\n",
    "        grad_b1 = np.zeros((16, 1))\n",
    "        grad_b2 = np.zeros((16, 1))\n",
    "        grad_b3 = np.zeros((10, 1))\n",
    "        \n",
    "        for image, label in batch:\n",
    "            # compute the output (image is equal to a0)\n",
    "            a1 = sigmoid(W1 @ image + b1)\n",
    "            a2 = sigmoid(W2 @ a1 + b2)\n",
    "            a3 = sigmoid(W3 @ a2 + b3)\n",
    "            \n",
    "            # ---- Last layer\n",
    "            # weight\n",
    "            grad_W3 += (2 * (a3 - label) * a3 * (1 - a3)) @ np.transpose(a2)\n",
    "            \n",
    "            # bias\n",
    "            grad_b3 += 2 * (a3 - label) * a3 * (1 - a3)\n",
    "            \n",
    "            # ---- 3rd layer\n",
    "            # activation\n",
    "            delta_3 = np.zeros((16, 1))\n",
    "            delta_3 += np.transpose(W3) @ (2 *(a3 - label) * (a3 * (1 - a3)))\n",
    "            \n",
    "            # weight\n",
    "            grad_W2 += (a2 * (1 - a2) * delta_3) @ np.transpose(a1)\n",
    "            \n",
    "            # bias\n",
    "            grad_b2 += delta_3 * a2 * (1 - a2)\n",
    "                    \n",
    "            # ---- 2nd layer\n",
    "            # activation\n",
    "            delta_2 = np.zeros((16, 1))\n",
    "            delta_2 += np.transpose(W2) @ delta_3 * a2 * (1 - a2)\n",
    "            \n",
    "            # weight\n",
    "            grad_W1 += (delta_2 * a1 * (1 - a1)) @ np.transpose(image)\n",
    "                    \n",
    "            # bias\n",
    "            grad_b1 += delta_2 * a1 * (1 - a1)\n",
    "        \n",
    "        W3 = W3 - (learning_rate * (grad_W3 / batch_size))\n",
    "        W2 = W2 - (learning_rate * (grad_W2 / batch_size))\n",
    "        W1 = W1 - (learning_rate * (grad_W1 / batch_size))\n",
    "        \n",
    "        b3 = b3 - (learning_rate * (grad_b3 / batch_size))\n",
    "        b2 = b2 - (learning_rate * (grad_b2 / batch_size))\n",
    "        b1 = b1 - (learning_rate * (grad_b1 / batch_size))\n",
    "    \n",
    "    # calculate cost average per epoch\n",
    "    cost = 0\n",
    "    for train_data in train_set[:100]:\n",
    "        a0 = train_data[0]\n",
    "        a1 = sigmoid(W1 @ a0 + b1)\n",
    "        a2 = sigmoid(W2 @ a1 + b2)\n",
    "        a3 = sigmoid(W3 @ a2 + b3)\n",
    "\n",
    "        for j in range(10):\n",
    "            cost += np.power((a3[j, 0] - train_data[1][j,  0]), 2)\n",
    "            \n",
    "    cost /= 100\n",
    "    total_costs.append(cost)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.67\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_size = [x for x in range(number_of_epochs)]\n",
    "plt.plot(epoch_size, total_costs)\n",
    "number_of_correct_estimations = 0\n",
    "for train_data in train_set[:100]:\n",
    "    a0 = train_data[0]\n",
    "    a1 = sigmoid(W1 @ a0 + b1)\n",
    "    a2 = sigmoid(W2 @ a1 + b2)\n",
    "    a3 = sigmoid(W3 @ a2 + b3)\n",
    "    \n",
    "    predicted_number = np.where(a3 == np.amax(a3))\n",
    "    real_number = np.where(train_data[1] == np.amax(train_data[1]))\n",
    "    \n",
    "    if predicted_number == real_number:\n",
    "        number_of_correct_estimations += 1\n",
    "        \n",
    "print(f\"Accuracy: {number_of_correct_estimations / 100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Testing the model\n",
    "We use all of our data (60k images) to learn our model now that we've optimized our implementation. Finally, we measure the model's accuracy using test results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "learning_rate = 1\n",
    "number_of_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total_costs = []\n",
    "# Initialize W with random normal distribution for each layer.\n",
    "W1 = np.random.normal(size=(16, NUMBER_OF_PIXELS))\n",
    "W2 = np.random.normal(size=(16, 16))\n",
    "W3 = np.random.normal(size=(10, 16))\n",
    "\n",
    "# Initialize b = 0, for each layer.\n",
    "b1 = np.zeros((16, 1))\n",
    "b2 = np.zeros((16, 1))\n",
    "b3 = np.zeros((10, 1))\n",
    "\n",
    "for epoch in range(number_of_epochs):\n",
    "    np.random.shuffle(train_set)\n",
    "    batches = [train_set[x:x+batch_size] for x in range(0, len(train_set), batch_size)]\n",
    "    for batch in batches:\n",
    "        # allocate grad_W matrix for each layer\n",
    "        grad_W1 = np.zeros((16, NUMBER_OF_PIXELS))\n",
    "        grad_W2 = np.zeros((16, 16))\n",
    "        grad_W3 = np.zeros((10, 16))\n",
    "        # allocate grad_b for each layer\n",
    "        grad_b1 = np.zeros((16, 1))\n",
    "        grad_b2 = np.zeros((16, 1))\n",
    "        grad_b3 = np.zeros((10, 1))\n",
    "        \n",
    "        for image, label in batch:\n",
    "            # compute the output (image is equal to a0)\n",
    "            a1 = sigmoid(W1 @ image + b1)\n",
    "            a2 = sigmoid(W2 @ a1 + b2)\n",
    "            a3 = sigmoid(W3 @ a2 + b3)\n",
    "            \n",
    "            # ---- Last layer\n",
    "            # weight\n",
    "            grad_W3 += (2 * (a3 - label) * a3 * (1 - a3)) @ np.transpose(a2)\n",
    "            \n",
    "            # bias\n",
    "            grad_b3 += 2 * (a3 - label) * a3 * (1 - a3)\n",
    "            \n",
    "            # ---- 3rd layer\n",
    "            # activation\n",
    "            delta_3 = np.zeros((16, 1))\n",
    "            delta_3 += np.transpose(W3) @ (2 *(a3 - label) * (a3 * (1 - a3)))\n",
    "            \n",
    "            # weight\n",
    "            grad_W2 += (a2 * (1 - a2) * delta_3) @ np.transpose(a1)\n",
    "            \n",
    "            # bias\n",
    "            grad_b2 += delta_3 * a2 * (1 - a2)\n",
    "                    \n",
    "            # ---- 2nd layer\n",
    "            # activation\n",
    "            delta_2 = np.zeros((16, 1))\n",
    "            delta_2 += np.transpose(W2) @ delta_3 * a2 * (1 - a2)\n",
    "            \n",
    "            # weight\n",
    "            grad_W1 += (delta_2 * a1 * (1 - a1)) @ np.transpose(image)\n",
    "                    \n",
    "            # bias\n",
    "            grad_b1 += delta_2 * a1 * (1 - a1)\n",
    "        \n",
    "        W3 = W3 - (learning_rate * (grad_W3 / batch_size))\n",
    "        W2 = W2 - (learning_rate * (grad_W2 / batch_size))\n",
    "        W1 = W1 - (learning_rate * (grad_W1 / batch_size))\n",
    "        \n",
    "        b3 = b3 - (learning_rate * (grad_b3 / batch_size))\n",
    "        b2 = b2 - (learning_rate * (grad_b2 / batch_size))\n",
    "        b1 = b1 - (learning_rate * (grad_b1 / batch_size))\n",
    "    \n",
    "    # calculate cost average per epoch\n",
    "    cost = 0\n",
    "    for train_data in train_set:\n",
    "        a0 = train_data[0]\n",
    "        a1 = sigmoid(W1 @ a0 + b1)\n",
    "        a2 = sigmoid(W2 @ a1 + b2)\n",
    "        a3 = sigmoid(W3 @ a2 + b3)\n",
    "\n",
    "        for j in range(10):\n",
    "            cost += np.power((a3[j, 0] - train_data[1][j,  0]), 2)\n",
    "            \n",
    "    cost /= 100\n",
    "    total_costs.append(cost)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.35\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfeUlEQVR4nO3deXiW9Z3v8fc3ISSQsAgJmAUIBFB2tBFxFKFal1Ykek2nh2lrvVpbBo8908W2lrHY01Jnujrn9MxxodUZbV3qnFqJ1LVWIlSRBoewuiQsEoIkgCxhC0m+54/nCTzGQJ6s97N8XtfF5Z3ffT/J198FH25+9+/5PubuiIhIYkkJugAREel+CncRkQSkcBcRSUAKdxGRBKRwFxFJQH2CLgAgOzvbCwsLgy5DRCSurF27dq+757R1LibCvbCwkPLy8qDLEBGJK2a240zntCwjIpKA2g13MxthZq+Y2RYz22RmXwuP/8zM3jKz9Wb2BzMbHPGaRWZWaWZvm9k1Pfk/ICIiHxXNnXsjcLu7TwBmAreZ2UTgJWCyu08F3gEWAYTPzQcmAdcC95pZak8ULyIibWs33N19t7u/GT4+DGwB8t39RXdvDF+2GigIH5cAT7j7CXffBlQCM7q/dBEROZMOrbmbWSFwAfBGq1NfAp4LH+cDOyPOVYfHWn+vBWZWbmbldXV1HSlDRETaEXW4m1kW8Hvg6+5+KGL8TkJLN4+2DLXx8o90J3P3pe5e7O7FOTlt7uQREZFOimorpJmlEQr2R939qYjxm4G5wJV+ur1kNTAi4uUFQE33lCsiItGIZreMAQ8CW9z9nojxa4E7gHnufjTiJaXAfDNLN7PRwDhgTfeWHbL/SAM/eGYTB4+d7IlvLyISt6K5c78UuAnYYGbrwmP/BPwSSAdeCuU/q919obtvMrMngc2Elmtuc/em7i8dag4c4+HXttPY5Cy5YXJP/AgRkbjUbri7+yraXkd/9iyvuRu4uwt1RWVy/iC+cEkhD7++nU9/rIBpIwa3+xoRkWQQ9+9Qvf3q8eRkpXPn0xtoatanSomIQAKE+4CMNO66fiIbdx3iN69vD7ocEZGYEPfhDnDdlFwuH5/Dz198hz2HjgddjohI4BIi3M2MH86bRENTM0uWbw66HBGRwCVEuAMUZmfy1Y+PZfn63bz6jt7xKiLJLWHCHeAfZo9hTHYmi5dt5PjJHtl9KSISFxIq3NP7pLLkhsns2HeUe1dUBV2OiEhgEircAS4dm03J9DzuX1HF1rr6oMsREQlEwoU7wJ3XTSA9LYXFyzZyuuWNiEjySMhwHzYgg+9ccx5/qdxHaYV6lolI8knIcAf47MWjmFYwiCXLt6ixmIgknYQN99QU4+4bp7D/yAl+8eLbQZcjItKrEjbc4XRjsd+s3kHFzgNBlyMi0msSOtxBjcVEJDklfLirsZiIJKOED3cINRabNS5bjcVEJGkkRbibGUtKJquxmIgkjaQIdwg1FrttjhqLiUhySJpwB1g4R43FRCQ5JFW4q7GYiCSLpAp3UGMxEUkOSRfuoMZiIpL4kjLc1VhMRBJdUoY7hBqLTVVjMRFJUO2Gu5mNMLNXzGyLmW0ys6+Fx4eY2Utm9m74v+dEvGaRmVWa2dtmdk1P/g90VmqKcfcNaiwmIokpmjv3RuB2d58AzARuM7OJwHeBl919HPBy+GvC5+YDk4BrgXvNLLUniu+qKQVqLCYiiandcHf33e7+Zvj4MLAFyAdKgIfDlz0M3BA+LgGecPcT7r4NqARmdHfh3eWbaiwmIgmoQ2vuZlYIXAC8AQx3990Q+gsAGBa+LB/YGfGy6vBY6++1wMzKzay8ri64d4wOzEhj8Vw1FhORxBJ1uJtZFvB74Ovufuhsl7Yx9pFbYndf6u7F7l6ck5MTbRk9Yu5UNRYTkcQSVbibWRqhYH/U3Z8KD+8xs9zw+VygNjxeDYyIeHkBENP7DdVYTEQSTTS7ZQx4ENji7vdEnCoFbg4f3wwsixifb2bpZjYaGAes6b6Se4Yai4lIIonmzv1S4CbgCjNbF/71KeDHwFVm9i5wVfhr3H0T8CSwGXgeuM3d46JL18I5YxidncldaiwmInHOYuHt98XFxV5eXh50GQCsencvn3/wDb525Ti+cdX4oMsRETkjM1vr7sVtnUvad6ieyWXjQo3F7lNjMRGJYwr3NrQ0Frtr2SY1FhORuKRwb0NLY7FVlXvVWExE4pLC/QxaGov96I9qLCYi8UfhfgYtjcX21auxmIjEH4X7WUQ2FltfrcZiIhI/FO7tONVY7A8b1VhMROKGwr0dLY3FNuw6yG9X7wi6HBGRqCjco3CqsdgLb1OrxmIiEgcU7lFoaSx2oqmZJX/cEnQ5IiLtUrhHqaWx2DMVNax8V43FRCS2Kdw7oKWx2OKn1VhMRGKbwr0D0vuksqRkMtv3HeW+FVVBlyMickYK9w66bFw286aFGott23sk6HJERNqkcO+E780NNRZb/PRGNRYTkZikcO+EYQMy+Ha4sdgz63cHXY6IyEco3Dvpc+HGYkuWb+bQcTUWE5HYonDvpA81FntBjcVEJLYo3LugpbHYI2osJiIxRuHeRd+8ejzZaiwmIjFG4d5FAzPSuEuNxUQkxijcu4Eai4lIrFG4dwMz44dqLCYiMUTh3k1GZ2fy3+cUqbGYiMSEdsPdzB4ys1oz2xgxNt3MVpvZOjMrN7MZEecWmVmlmb1tZtf0VOGxaOHsIjUWE5GYEM2d+38A17Ya+ynwA3efDtwV/hozmwjMByaFX3OvmaV2W7UxLiNNjcVEJDa0G+7u/iqwv/UwMDB8PAioCR+XAE+4+wl33wZUAjNIImosJiKxoLNr7l8HfmZmO4GfA4vC4/nAzojrqsNjH2FmC8JLOuV1dYm1Rv29uRNI76PGYiISnM6G+63AN9x9BPAN4MHwuLVxbZvp5u5L3b3Y3YtzcnI6WUZsGjYgg29fq8ZiIhKczob7zcBT4eP/5PTSSzUwIuK6Ak4v2SQVNRYTkSB1NtxrgNnh4yuAd8PHpcB8M0s3s9HAOGBN10qMT2osJiJB6tPeBWb2ODAHyDazauD7wFeA/21mfYDjwAIAd99kZk8Cm4FG4DZ3T9o9gVMKBnHTzFE8snoHf/uxAqYWDA66JBFJEhYLD/yKi4u9vLw86DJ6xKHjJ7nyF2WcOzCDp2+7lNSUth5LiIh0nJmtdffits7pHao9bGBGGovVWExEepnCvRdcr8ZiItLLFO69QI3FRKS3Kdx7iRqLiUhvUrj3ooWziygc2l+NxUSkxynce1FGWipLbgg1Fru/TI3FRKTnKNx72axxOVw/LY97X1FjMRHpOQr3ACy+LtRY7K5laiwmIj1D4R6AYQMz+NY157HyXTUWE5GeoXAPyOdnjmJKvhqLiUjPULgHJDXF+Ocb1VhMRHqGwj1ALY3FfrN6B+urDwRdjogkEIV7wG6/5jyGZqVz5x820tSsh6si0j0U7gGLbCz26BtqLCYi3UPhHgNaGov97Hk1FhOR7qFwjwGRjcV+pMZiItINFO4xoqWxWKkai4lIN1C4x5CWxmJ3LdukxmIi0iUK9xjS0lhs294jaiwmIl2icI8xpxqLrVBjMRHpPIV7DFp83QTSU9VYTEQ6T+EegyIbiy1XYzER6QSFe4xqaSz2QzUWE5FOULjHqNQU4+4bJ7O3/gT3vPhO0OWISJxRuMewqQWD+cLMUTzy+nY2VB8MuhwRiSPthruZPWRmtWa2sdX4/zCzt81sk5n9NGJ8kZlVhs9d0xNFJ5NTjcWe3qDGYiIStWju3P8DuDZywMw+DpQAU919EvDz8PhEYD4wKfyae80stTsLTjYtjcXWV6uxmIhEr91wd/dXgf2thm8FfuzuJ8LX1IbHS4An3P2Eu28DKoEZ3VhvUrp+ai6XjQ03FjusxmIi0r7OrrmPB2aZ2RtmVmZmF4XH84GdEddVh8c+wswWmFm5mZXX1amXytmYGUtuCDcWW67GYiLSvs6Gex/gHGAm8G3gSTMzwNq4ts2FYndf6u7F7l6ck5PTyTKSx+jsTG6dHWosturdvUGXIyIxrrPhXg085SFrgGYgOzw+IuK6AqCmayVKi1vnhBqLLV62UY3FROSsOhvuTwNXAJjZeKAvsBcoBeabWbqZjQbGAWu6o1BRYzERiV40WyEfB14HzjOzajO7BXgIGBPeHvkEcHP4Ln4T8CSwGXgeuM3ddYvZjdRYTESiYbHQmKq4uNjLy8uDLiNu1B46zpW/KGP6yME88qUZhB53iEiyMbO17l7c1jm9QzUOqbGYiLRH4R6n1FhMRM5G4R6n1FhMRM5G4R7HphYM5iY1FhORNijc49y31FhMRNqgcI9zAzPS+N51E9RYTEQ+ROGeAOZNy1NjMRH5EIV7AjAzflgyiRONaiwmIiEK9wQxJieLW+eosZiIhCjcE4gai4lIC4V7AslIS+WHJaHGYg+UbQ26HBEJkMI9wVw+Poe5U3P5vysq2a7GYiJJS+GegBbPnUh6agqLl20kFhrDiUjvU7gnoOEDM7j96vFqLCaSxBTuCeqmSwqZkj+IJWosJpKUFO4JqqWxWJ0ai4kkJYV7AlNjMZHkpXBPcLdffR5DMtVYTCTZKNwT3KB+aSyeG2os9pgai4kkDYV7Epg3LY9Lxw7lp2osJpI0FO5JwMxYUjKZE43N3P1HNRYTSQYK9yTR0lhs2boafvL8W+ytPxF0SSLSg/oEXYD0nlvnFFFVV8/9ZVU8tGobnykewVdmjWHk0P5BlyYi3cxi4e3pxcXFXl5eHnQZSaOqrp6lZVt56r+qaWp2rpuax8LZY5iUNyjo0kSkA8xsrbsXt3Wu3WUZM3vIzGrNbGMb575lZm5m2RFji8ys0szeNrNrula69ISinCx+8umprPzOFXx51hheeauW6365ii88tIbXqvaqH41IAmj3zt3MLgfqgUfcfXLE+Ajg18D5wMfcfa+ZTQQeB2YAecCfgPHuftbm4rpzD9bBYyf57eod/PtftrG3voFpBYNYOLuIqyedS2qKBV2eiJxBl+7c3f1VYH8bp/4V+A4Q+bdDCfCEu59w921AJaGglxg2qF8at318LKvuuIIf3TCZA8dOcuujb3LVPWU8vuY9TjTqgz9E4k2ndsuY2Txgl7tXtDqVD+yM+Lo6PNbW91hgZuVmVl5XV9eZMqSbZaSl8vmZo/jz7XP4t89eQP/0VBY9tYFZP3mF+8uqOKwGZCJxo8Phbmb9gTuBu9o63cZYm+s+7r7U3YvdvTgnJ6ejZUgPSk0x5k7N45mvXsZvb7mYccOz+PFzb/E3//JnfvL8W3ojlEgc6MxWyCJgNFBhZgAFwJtmNoPQnfqIiGsLgJquFinBMDMuG5fNZeOy2VB9kPvLqnigrIoHV23jby8sYMHlYxidnRl0mSLShqi2QppZIbA88oFqxLntQHH4geok4DFOP1B9GRinB6qJY/veIyxduZX/t7aak03NfHLyuSycXcTUgsFBlyaSdLq6FfJx4HXgPDOrNrNbznStu28CngQ2A88Dt7UX7BJfCrMz+ecbp7Dqjo+zcHYRK9/Zy7x/+wuf+/VqVr5bp22UIjFCb2KSLjl8/CSPvfEeD67aRu3hE0zKG8jC2UV8akqutlGK9LCz3bkr3KVbnGhs4g9v7mLpq1vZuvcIo4b25yuzxvDpjxWQkZYadHkiCUnhLr2mqdl5afP73Fe2lYqdB8jO6ssXLx3N52eOYlC/tKDLE0koCnfpde7O6q37ub+sirJ36sjsm8pnLx7JLZeN4dxBGUGXJ5IQFO4SqE01B3mgbCvL19eQmmLceEE+Cy4vYuywrKBLE4lrCneJCTv3H+VXK7fyu7/upKGpmasmDGfhnCIuHHlO0KWJxCWFu8SUvfUnePi17Tzy+g4OHjvJxaOHsHBOEXPG5xB+Y5yIREHhLjHpyIlGHl8T2ka5++Bxzj93AAtnFzF3ai59UvUhYSLtUbhLTGtobKa0ooYHyqp4t7aegnP68ZVZY/hM8Qj69dU2SpEzUbhLXGhudl5+q5b7y6pYu+MDhmT25eZLCvnCJaM4J7Nv0OWJxByFu8Sdv27fz30rqvjzW7X075vK/ItG8uVZo8kb3C/o0kRihsJd4tbb7x/mgbIqSitCzUXnTc9j4ewixg8fEHBlIsFTuEvc23XgGL9euZUn1uzk2Mkmrjx/GAvnFHFR4ZCgSxMJjMJdEsYHRxp4+PXtPPzadj44epLiUeewcHYRV5w/jBQ1KpMko3CXhHO0oZEn/7qTX63cxq4Dxxg/PIt/uLyIedPzSNM2SkkSCndJWCebmvnj+t3cX1bFW+8fJm9QBrfMGsP8i0aQmd6ZDxoTiR8Kd0l47s6Kt+u4r6yKNdv2M6hfGjdfMoqb/6aQoVnpQZcn0iMU7pJU3nzvA+5fUcWLm/eQkZbCfysewZdnjWHEkP5BlybSrRTukpQqaw/zQNlWnl63i2aHuVNzWTi7iAm5A4MuTaRbKNwlqe0+eIyHVm3jsTfe40hDE3POy2Hh7CIuHj1EjcokrincRYCDR0/y2zd28O9/2cbe+gamjxjMwtlFXD1xuLZRSlxSuItEOH6yif9cW82vXt3Ke/uPMiYnk4WXF1FyQR7pfdSoTOKHwl2kDY1NzTy38X3uW1HF5t2HGD4wnVsuG83fzxjJgAx93qvEPoW7yFm4Oyvf3cv9ZVW8VrWPARl9uGnmKL546WhyBmgbpcQuhbtIlCp2HuCBV6t4buP7pKWm8HcfK+BzF49iQu4APXyVmNOlcDezh4C5QK27Tw6P/Qy4HmgAqoAvuvuB8LlFwC1AE/CP7v5CewUq3CXWbK2r51crt/L7tbtoaGpm3LAs5k3LY970PEYNzQy6PBGg6+F+OVAPPBIR7lcDf3b3RjP7CYC732FmE4HHgRlAHvAnYLy7N53tZyjcJVbtP9LAsxt2U7quhjXb9wMwbcRg5k3L4/qpuQwbmBFwhZLMurwsY2aFwPKWcG917kbg0+7+ufBdO+7+L+FzLwD/091fP9v3V7hLPKg5cIzl62tYtq6GTTWHMINLxgxl3rQ8Pjk5l0H99RBWetfZwr07Oit9Cfhd+DgfWB1xrjo81lZRC4AFACNHjuyGMkR6Vt7gfiy4vIgFlxdRWVtPaUUNz1TU8N2nNrB42UZmjx/GvOl5fGLCMPr3VdMyCVaXfgea2Z1AI/Boy1Abl7X5TwN3XwoshdCde1fqEOltY4dl8c2rxvONT4xj465DlFbs4pmK3fxpyx76903lqonDmTctj1njcujbRy2Ipfd1OtzN7GZCD1qv9NNrO9XAiIjLCoCazpcnEtvMjCkFg5hSMIhFn5zAmu37Ka2o4dkNu1m2robB/dP45ORc5k3L4+LRQ/ROWOk1nVpzN7NrgXuA2e5eF3HdJOAxTj9QfRkYpweqkmwaGptZVVlH6boaXty8h6MNTQwfmM71U0M7bqbkD9LWSumyru6WeRyYA2QDe4DvA4uAdGBf+LLV7r4wfP2dhNbhG4Gvu/tz7RWocJdEdrShkZe31LJsXQ1l79RysskZnZ3J9dPymDctj7HDsoIuUeKU3sQkEiMOHj3J85tCSzavb92HO0zMHUjJ9Dyun5ZH3uB+QZcocUThLhKDag8dZ/n63SyrqKFi5wEALio8h3nT8/nU5HP1CVLSLoW7SIzbse8Iz1SE9tC/W1tPaopx2dhsSqbncfWkc8nS58FKGxTuInHC3Xnr/cOUVtRQuq6GXQeOkd4nhSsnDGPetHzmnJdDRpraEkuIwl0kDrk7b773AaXrali+fjf7jjQwIL0P10w+l5LpeVwyZih9UrWHPpkp3EXiXGNTM69V7aO0ooYXNr7P4RONZGf1Ze7U0IPYC0cO1tbKJKRwF0kgx082seLtWkoravjTlloaGpspOKffqa6V55+rDwBPFgp3kQR1+PhJXty0h9KKGlZV7qWp2Rk/PNyeeFo+I4f2D7pE6UEKd5EksK/+RKg9cUUNf93+AQDTRwymZHoe103NZdgAtSdONAp3kSSz68AxngnvuNm8+xApBpcUhdoTXztJ7YkThcJdJIlV1h6mdF0NpRU1bN93lL6pKcw+L4eS6Xlcef5w+vXV1sp4pXAXEdyd9dUHKa2oYfn6GvYcOkFmuD1xyfR8LhuXTZq2VsYVhbuIfEhTs/PGtn08U1HDsxve5+Cxk5zTP41PTsmlZFoeFxWqPXE8ULiLyBk1NDbz6jt1lFbU8NLmPRw72UTuoAzmTs2lZHo+k/IGag99jFK4i0hUjjY08tLmPTxTUUPZO3WcbHLGtLQnnp5HUY7aE8cShbuIdNiBow08t/F9StfVsHpbqD3x5PyBzJsWelds7iC1Jw6awl1EumTPoeM8E/5A8Irqg5jBRYVDmDctj09NyWVIZt+gS0xKCncR6Tbb9x4Jda2sqKGytp4+KcascdnMm57HVRPVnrg3KdxFpNu5O1t2H2ZZxS6WV+xm14FjZKSlMLVgMEU5WRTlZDJ2WBZFOVnkD+6n3Tc9QOEuIj2quTnUnnj5+t1s3HWQyrp6Dhw9eep8RloKY7KzToV90bBQ8BcOzVR/+i44W7jr308i0mUpKUZx4RCKC4cAobv6/UcaqKo7QmVtPVV19VTW1of601fUnH6dwYgh/SnKaQn+zFPHg/trHb8rFO4i0u3MjKFZ6QzNSmfG6CEfOnesoYmte+s/FPxVtfWsqtxLQ2PzqeuGZvalKHyn3xL8Y4dlkTdISzzRULiLSK/q1zeVSXmDmJQ36EPjTc1O9QdHw2F/Ovif27j7Q0s8/dJSGRO+wz8V/MMytcTTisJdRGJCaooxamgmo4ZmcsX5p8c7usQzNicrfMd/+oFuMi7xKNxFJKZ1ZolnZaslnuysvozJiXigmwRLPO2Gu5k9BMwFat19cnhsCPA7oBDYDnzG3T8In1sE3AI0Af/o7i/0SOUikvQ6usTz7IYzL/FE7uRJhCWedrdCmtnlQD3wSES4/xTY7+4/NrPvAue4+x1mNhF4HJgB5AF/Asa7e9PZfoa2QopIb2hZ4gmF/ZFTSzxVdfVUf3Ds1HWtl3jGtmzfzBkQUx900qWtkO7+qpkVthouAeaEjx8GVgB3hMefcPcTwDYzqyQU9K93pnARke4UucRz8ZihHzrXssQTGfzRLPG07OSJtSWezq65D3f33QDuvtvMhoXH84HVEddVh8dERGJaNEs8lbWhZZ5ol3jGDsuiMLs/6X16f4mnux+otvXXVpvrPma2AFgAMHLkyG4uQ0Ske3x4F8/wU+Otl3halnfa2sUzMvxGrd5c4ulsuO8xs9zwXXsuUBserwZGRFxXANR85NWAuy8FlkJozb2TdYiIBKK7lnhumJ7P9+ZO7Pb6OhvupcDNwI/D/10WMf6Ymd1D6IHqOGBNV4sUEYknHVniyR3cM33xo9kK+Tihh6fZZlYNfJ9QqD9pZrcA7wF/B+Dum8zsSWAz0Ajc1t5OGRGRZHGmJZ6eEM1umb8/w6krz3D93cDdXSlKRES6JiXoAkREpPsp3EVEEpDCXUQkASncRUQSkMJdRCQBKdxFRBKQwl1EJAG12/K3V4owqwN2dOFbZAN7u6mc7qS6OkZ1dYzq6phErGuUu+e0dSImwr2rzKz8TD2Ng6S6OkZ1dYzq6phkq0vLMiIiCUjhLiKSgBIl3JcGXcAZqK6OUV0do7o6JqnqSog1dxER+bBEuXMXEZEICncRkQQUN+FuZtea2dtmVmlm323jvJnZL8Pn15vZhTFS1xwzO2hm68K/7uqluh4ys1oz23iG80HNV3t19fp8mdkIM3vFzLaY2SYz+1ob1wQ1X9HUFsScZZjZGjOrCNf1gzau6fU5i7KuoP5MpprZf5nZ8jbOdf9cuXvM/wJSgSpgDNAXqAAmtrrmU8BzhD6keybwRozUNQdYHsCcXQ5cCGw8w/len68o6+r1+QJygQvDxwOAd2Lh91cHagtizgzICh+nAW8AM4OesyjrCurP5DeBx9r62T0xV/Fy5z4DqHT3re7eADwBlLS6pgR4xENWA4PDH94ddF2BcPdXgf1nuSSI+Yqmrl7n7rvd/c3w8WFgC5Df6rKg5iua2npdeB7qw1+mhX+13p3R63MWZV29zswKgOuAX5/hkm6fq3gJ93xgZ8TX1Xz0N3g01wRRF8Al4X8mPmdmk3q4pmgFMV/RCmy+zKwQuIDQHV+kwOfrLLVBAHMWXmZYB9QCL7l7TMxZFHVB78/X/wK+AzSf4Xy3z1W8hLu1Mdb6b+Norulu0fzMNwn1f5gG/B/g6R6uKVpBzFc0ApsvM8sCfg983d0PtT7dxkt6bb7aqS2QOXP3JnefDhQAM8xscqtLApmzKOrq1fkys7lArbuvPdtlbYx1aa7iJdyrgRERXxcANZ24ptfrcvdDLf9MdPdngTQzy+7huqIRxHy1K6j5MrM0QuH5qLs/1cYlgc1Xe7UF/XvM3Q8AK4BrW50K9PfYmeoKYL4uBeaZ2XZCS7dXmNlvW13T7XMVL+H+V2CcmY02s77AfKC01TWlwBfCT51nAgfdfXfQdZnZuWZm4eMZhOZ8Xw/XFY0g5qtdQcxX+Oc9CGxx93vOcFkg8xVNbQHNWY6ZDQ4f9wM+AbzV6rJen7No6urt+XL3Re5e4O6FhDLiz+7++VaXdftc9enKi3uLuzea2VeBFwjtUHnI3TeZ2cLw+fuBZwk9ca4EjgJfjJG6Pg3camaNwDFgvocfj/ckM3uc0K6AbDOrBr5P6OFSYPMVZV1BzNelwE3AhvBaLcA/ASMj6gpkvqKsLYg5ywUeNrNUQuH4pLsvD/rPZJR1BfJnsrWeniu1HxARSUDxsiwjIiIdoHAXEUlACncRkQSkcBcRSUAKdxGRBKRwFxFJQAp3EZEE9P8BzyB9I1Y3NDEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_size = [x for x in range(number_of_epochs)]\n",
    "plt.plot(epoch_size, total_costs)\n",
    "number_of_correct_estimations = 0\n",
    "for test_data in test_set:\n",
    "    a0 = test_data[0]\n",
    "    a1 = sigmoid(W1 @ a0 + b1)\n",
    "    a2 = sigmoid(W2 @ a1 + b2)\n",
    "    a3 = sigmoid(W3 @ a2 + b3)\n",
    "    \n",
    "    predicted_number = np.where(a3 == np.amax(a3))\n",
    "    real_number = np.where(test_data[1] == np.amax(test_data[1]))\n",
    "    \n",
    "    if predicted_number == real_number:\n",
    "        number_of_correct_estimations += 1\n",
    "        \n",
    "print(f\"Accuracy: {number_of_correct_estimations / 100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Additional Steps\n",
    "    6.1 Shifting image  \n",
    "    6.2 Using another activation function  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Shifting image\n",
    "In this section, we examine the consequence of shifting input images of the test set and its effect on the accuracy of our model. To do that, we can divide this section into two steps:\n",
    "1. Training our model with full of the train set images.\n",
    "2. test our model with a shifted version of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#1\n",
    "\n",
    "total_costs = []\n",
    "# Initialize W with random normal distribution for each layer.\n",
    "W1 = np.random.normal(size=(16, NUMBER_OF_PIXELS))\n",
    "W2 = np.random.normal(size=(16, 16))\n",
    "W3 = np.random.normal(size=(10, 16))\n",
    "\n",
    "# Initialize b = 0, for each layer.\n",
    "b1 = np.zeros((16, 1))\n",
    "b2 = np.zeros((16, 1))\n",
    "b3 = np.zeros((10, 1))\n",
    "\n",
    "for epoch in range(number_of_epochs):\n",
    "    np.random.shuffle(train_set)\n",
    "    batches = [train_set[x:x+batch_size] for x in range(0, len(train_set), batch_size)]\n",
    "    for batch in batches:\n",
    "        # allocate grad_W matrix for each layer\n",
    "        grad_W1 = np.zeros((16, NUMBER_OF_PIXELS))\n",
    "        grad_W2 = np.zeros((16, 16))\n",
    "        grad_W3 = np.zeros((10, 16))\n",
    "        # allocate grad_b for each layer\n",
    "        grad_b1 = np.zeros((16, 1))\n",
    "        grad_b2 = np.zeros((16, 1))\n",
    "        grad_b3 = np.zeros((10, 1))\n",
    "        \n",
    "        for image, label in batch:\n",
    "            # compute the output (image is equal to a0)\n",
    "            a1 = sigmoid(W1 @ image + b1)\n",
    "            a2 = sigmoid(W2 @ a1 + b2)\n",
    "            a3 = sigmoid(W3 @ a2 + b3)\n",
    "            \n",
    "            # ---- Last layer\n",
    "            # weight\n",
    "            grad_W3 += (2 * (a3 - label) * a3 * (1 - a3)) @ np.transpose(a2)\n",
    "            \n",
    "            # bias\n",
    "            grad_b3 += 2 * (a3 - label) * a3 * (1 - a3)\n",
    "            \n",
    "            # ---- 3rd layer\n",
    "            # activation\n",
    "            delta_3 = np.zeros((16, 1))\n",
    "            delta_3 += np.transpose(W3) @ (2 *(a3 - label) * (a3 * (1 - a3)))\n",
    "            \n",
    "            # weight\n",
    "            grad_W2 += (a2 * (1 - a2) * delta_3) @ np.transpose(a1)\n",
    "            \n",
    "            # bias\n",
    "            grad_b2 += delta_3 * a2 * (1 - a2)\n",
    "                    \n",
    "            # ---- 2nd layer\n",
    "            # activation\n",
    "            delta_2 = np.zeros((16, 1))\n",
    "            delta_2 += np.transpose(W2) @ delta_3 * a2 * (1 - a2)\n",
    "            \n",
    "            # weight\n",
    "            grad_W1 += (delta_2 * a1 * (1 - a1)) @ np.transpose(image)\n",
    "                    \n",
    "            # bias\n",
    "            grad_b1 += delta_2 * a1 * (1 - a1)\n",
    "        \n",
    "        W3 = W3 - (learning_rate * (grad_W3 / batch_size))\n",
    "        W2 = W2 - (learning_rate * (grad_W2 / batch_size))\n",
    "        W1 = W1 - (learning_rate * (grad_W1 / batch_size))\n",
    "        \n",
    "        b3 = b3 - (learning_rate * (grad_b3 / batch_size))\n",
    "        b2 = b2 - (learning_rate * (grad_b2 / batch_size))\n",
    "        b1 = b1 - (learning_rate * (grad_b1 / batch_size))\n",
    "    \n",
    "    # calculate cost average per epoch\n",
    "    cost = 0\n",
    "    for train_data in train_set:\n",
    "        a0 = train_data[0]\n",
    "        a1 = sigmoid(W1 @ a0 + b1)\n",
    "        a2 = sigmoid(W2 @ a1 + b2)\n",
    "        a3 = sigmoid(W3 @ a2 + b3)\n",
    "\n",
    "        for j in range(10):\n",
    "            cost += np.power((a3[j, 0] - train_data[1][j,  0]), 2)\n",
    "            \n",
    "    cost /= 100\n",
    "    total_costs.append(cost)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on to the second step, we construct a function that shifts the given image 4 pixels to the right. As a result, the image's last four columns are removed, and the first four columns' pixels are replaced with black pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_image(given_flat_image):\n",
    "    image = given_flat_image.reshape(28, 28)\n",
    "    shifted_image = np.roll(image, 4)\n",
    "    shifted_image[:, 0] = np.zeros(28)\n",
    "    shifted_image[:, 1] = np.zeros(28)\n",
    "    shifted_image[:, 2] = np.zeros(28)\n",
    "    shifted_image[:, 3] = np.zeros(28)\n",
    "    \n",
    "    return shifted_image.reshape(784, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 25.66\n"
     ]
    }
   ],
   "source": [
    "number_of_correct_estimations = 0\n",
    "for test_data in test_set:\n",
    "    a0 = shift_image(test_data[0])\n",
    "    a1 = sigmoid(W1 @ a0 + b1)\n",
    "    a2 = sigmoid(W2 @ a1 + b2)\n",
    "    a3 = sigmoid(W3 @ a2 + b3)\n",
    "    \n",
    "    predicted_number = np.where(a3 == np.amax(a3))\n",
    "    real_number = np.where(test_data[1] == np.amax(test_data[1]))\n",
    "    \n",
    "    if predicted_number == real_number:\n",
    "        number_of_correct_estimations += 1\n",
    "        \n",
    "print(f\"Accuracy: {number_of_correct_estimations / 100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see from the result of the above segment, the accuracy <span style=\"color:red\">has been reduced significantly</span>.\n",
    ".  \n",
    "\n",
    "**But why a 4 pixel shift to the right make it worse?** That's because the weights of the connections from all of the neurons from the first layer to a given neuron from the second layer create a pattern that, in the end, it leads to the diagnosis of which digit we're dealing with. But that only depends on the pixels that our model learns during the learning process. As a matter of fact, our model doesn't have the faintest idea of what's the meaning of each digit. It just knows what pixels on each position can lead to an expected result if they gather in one image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Using another activation function \n",
    "We have several activation functions such as Sigmoid, Tanh, ReLU, and suchlike. Every one of them has its own cons and pros based on the application. In this part, we train our model with the ReLU function instead of the sigmoid.\n",
    "![ReLU](assets/ReLU.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    result = np.array(x)\n",
    "    result[result < 0] = 0\n",
    "    return result\n",
    "\n",
    "def ReLU_derivative(x):\n",
    "    result = np.zeros((x.shape[0], 1))\n",
    "    result[x > 0] = 1\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total_costs = []\n",
    "# Initialize W with random normal distribution for each layer.\n",
    "W1 = np.random.normal(size=(16, NUMBER_OF_PIXELS))\n",
    "W2 = np.random.normal(size=(16, 16))\n",
    "W3 = np.random.normal(size=(10, 16))\n",
    "\n",
    "# Initialize b = 0, for each layer.\n",
    "b1 = np.zeros((16, 1))\n",
    "b2 = np.zeros((16, 1))\n",
    "b3 = np.zeros((10, 1))\n",
    "\n",
    "for epoch in range(number_of_epochs):\n",
    "    np.random.shuffle(train_set)\n",
    "    batches = [train_set[x:x+batch_size] for x in range(0, len(train_set), batch_size)]\n",
    "    for batch in batches:\n",
    "        # allocate grad_W matrix for each layer\n",
    "        grad_W1 = np.zeros((16, NUMBER_OF_PIXELS))\n",
    "        grad_W2 = np.zeros((16, 16))\n",
    "        grad_W3 = np.zeros((10, 16))\n",
    "        # allocate grad_b for each layer\n",
    "        grad_b1 = np.zeros((16, 1))\n",
    "        grad_b2 = np.zeros((16, 1))\n",
    "        grad_b3 = np.zeros((10, 1))\n",
    "        \n",
    "        for image, label in batch:\n",
    "            # compute the output (image is equal to a0)\n",
    "            z1 = W1 @ image + b1\n",
    "            a1 = ReLU(z1)\n",
    "            z2 = W2 @ a1 + b2\n",
    "            a2 = ReLU(z2)\n",
    "            z3 = W3 @ a2 + b3\n",
    "            a3 = ReLU(z3)\n",
    "            \n",
    "            # ---- Last layer\n",
    "            # weight\n",
    "            grad_W3 += (2 * (a3 - label) * ReLU_derivative(z3)) @ np.transpose(a2)\n",
    "                        \n",
    "            # bias\n",
    "            grad_b3 += 2 * (a3 - label) * ReLU_derivative(z3)\n",
    "            \n",
    "            # ---- 3rd layer\n",
    "            # activation\n",
    "            delta_3 = np.zeros((16, 1))\n",
    "            delta_3 += np.transpose(W3) @ (2 *(a3 - label) * ReLU_derivative(z3))\n",
    "            \n",
    "            # weight\n",
    "            grad_W2 += (ReLU_derivative(z2) * delta_3) @ np.transpose(a1)\n",
    "            \n",
    "            # bias\n",
    "            grad_b2 += delta_3 * ReLU_derivative(z2)\n",
    "                    \n",
    "            # ---- 2nd layer\n",
    "            # activation\n",
    "            delta_2 = np.zeros((16, 1))\n",
    "            delta_2 += np.transpose(W2) @ delta_3 * ReLU_derivative(z2)\n",
    "            \n",
    "            # weight\n",
    "            grad_W1 += (delta_2 * ReLU_derivative(z1)) @ np.transpose(image)\n",
    "                    \n",
    "            # bias\n",
    "            grad_b1 += delta_2 * ReLU_derivative(z1)\n",
    "        \n",
    "        W3 = W3 - (learning_rate * (grad_W3 / batch_size))\n",
    "        W2 = W2 - (learning_rate * (grad_W2 / batch_size))\n",
    "        W1 = W1 - (learning_rate * (grad_W1 / batch_size))\n",
    "        \n",
    "        b3 = b3 - (learning_rate * (grad_b3 / batch_size))\n",
    "        b2 = b2 - (learning_rate * (grad_b2 / batch_size))\n",
    "        b1 = b1 - (learning_rate * (grad_b1 / batch_size))\n",
    "    \n",
    "    # calculate cost average per epoch\n",
    "    cost = 0\n",
    "    for train_data in train_set:\n",
    "        a0 = train_data[0]\n",
    "        a1 = ReLU(W1 @ a0 + b1)\n",
    "        a2 = ReLU(W2 @ a1 + b2)\n",
    "        a3 = ReLU(W3 @ a2 + b3)\n",
    "        \n",
    "        for j in range(10):\n",
    "            cost += np.power((a3[j, 0] - train_data[1][j,  0]), 2)\n",
    "            \n",
    "    cost /= 100\n",
    "    total_costs.append(cost)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_size = [x for x in range(number_of_epochs)]\n",
    "plt.plot(epoch_size, total_costs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen in the diagram above. Negative values are mapped to zero in ReLU. In layer calculations, we always end up with a negative value. As a result, each perceptron's value at the last layer is always 0, and each image's cost is always 1. This is called [Dying ReLU](https://arxiv.org/abs/1903.06733)\n",
    "\n",
    "When we have millions of train data and the number of layers is too much, the ReLU function is appropriate. Since the sigmoid derivative is a number between 0 and 1, their output will be a number close to zero, and the learning process will suffer as a result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
